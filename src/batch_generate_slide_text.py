from prompt import build_prompt


import os
import json
import re
from datetime import datetime
from pathlib import Path
from dotenv import load_dotenv
from openai import OpenAI

from pathlib import Path
from dotenv import load_dotenv

# í˜„ì¬ íŒŒì¼ ê¸°ì¤€ ê²½ë¡œ ì„¤ì •
ROOT_DIR = Path(__file__).resolve().parents[1]  # í”„ë¡œì íŠ¸ ë£¨íŠ¸
SCRIPT_DIR = Path(__file__).resolve().parent  # í˜„ì¬ scripts í´ë”
load_dotenv(SCRIPT_DIR / ".env", override=True)  # .envê°€ scripts í´ë”ì— ìˆì„ ê²½ìš°

if not os.getenv("OPENAI_API_KEY"):
    raise RuntimeError(
        "OPENAI_API_KEYë¥¼ ë¶ˆëŸ¬ì˜¤ì§€ ëª»í–ˆìŠµë‹ˆë‹¤. .env ìœ„ì¹˜ì™€ í‚¤ ê°’ì„ ë‹¤ì‹œ í™•ì¸í•˜ì„¸ìš”."
    )

DATA_PATH = ROOT_DIR / ".data" / "EX2.json"
OUTPUT_DIR = ROOT_DIR / "slides"

IMMUTABLE_META_KEYS = {"leftNumber", "leftTitle", "leftSubtitle", "rightTitle", "rightNumber"}

client = OpenAI()

# ---------------------------
# ëª¨ë¸ ì„¤ì •
# ---------------------------
MODEL = "o4-mini-2025-04-16"
client = OpenAI()


# ---------------------------
# JSON ë¸”ë¡ ì¶”ì¶œ (--- ë˜ëŠ” {â€¦})
# ---------------------------

def save_split_json_results(content: str, start:int, end:int, output_dir: Path, prefix: str = "slide") -> list[Path]:
    """
    GPT ê²°ê³¼ í…ìŠ¤íŠ¸(content)ë¥¼ ë°›ì•„ì„œ
    '---' ê¸°ì¤€ìœ¼ë¡œ JSON ë¸”ë¡ì„ ë¶„ë¦¬ í›„ ê°ê° íŒŒì¼ë¡œ ì €ì¥í•˜ëŠ” í•¨ìˆ˜.
    """

    # ì—†ìœ¼ë©´, í´ë” ë§Œë“¤ê¸°
    output_dir.mkdir(parents=True, exist_ok=True)

    # --- êµ¬ë¶„ ê¸°ì¤€ìœ¼ë¡œ ë¶„ë¦¬
    parts = re.split(r"\n?---+\n?", content)
    parts = [p.strip() for p in parts if p.strip()]

    saved_files = []
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")

    # ê° ë¸”ë¡ JSON íŒŒì‹± + ì €ì¥
    for idx, block in enumerate(parts, start=start):
        try:
            data = json.loads(block)
        except json.JSONDecodeError:
            print(f">> JSON íŒŒì‹± ì‹¤íŒ¨ (#{idx}) â†’ í…ìŠ¤íŠ¸ë¡œ ì €ì¥")
            data = {"raw_text": block}

        # íŒŒì¼ ì €ì¥
        out_path = output_dir / f"{prefix}{idx}_{timestamp}.json"
        with out_path.open("w", encoding="utf-8") as f:
            json.dump(data, f, ensure_ascii=False, indent=2)

        saved_files.append(out_path)
        print(f"âœ… {prefix}{idx} ì €ì¥ ì™„ë£Œ â†’ {out_path}")

    print(f"\n ì´ {len(saved_files)}ê°œ JSON ì €ì¥ ì™„ë£Œ")
    return saved_files

# ---------------------------
# GPT í˜¸ì¶œ (ë°°ì¹˜ ì²˜ë¦¬)
# ---------------------------

import json
import re
from datetime import datetime
from pathlib import Path



def call_gpt_with_context(html: str, instruction: str) -> list[dict]:
    """í•˜ë‚˜ì˜ HTMLê³¼ instruction(ë°°ì¹˜ ë‹¨ìœ„ í”„ë¡¬í”„íŠ¸)ì„ ì…ë ¥ë°›ì•„ ì—¬ëŸ¬ JSON ê²°ê³¼ë¥¼ ë°˜í™˜"""
    resp = client.chat.completions.create(
        model=MODEL,
        messages=[
            {"role": "system", "content": "ì£¼ì–´ì§„ HTMLì •ë³´ë¡œ IR Deck ìŠ¬ë¼ì´ë“œë¥¼ ë§Œë“¤ì–´ì•¼í•´. ë„ˆëŠ” HTML ì •ë³´ë¥¼ ì‚¬ìš©í•´ ìŠ¬ë¼ì´ë“œë³„ í•„ìš”í•œ í…ìŠ¤íŠ¸ë¥¼ JSONìœ¼ë¡œ êµ¬ì¡°í™”í•˜ëŠ” ì „ë¬¸ê°€ì•¼."},
            {"role": "user", "content": f"ë‹¤ìŒì€ HTML ì „ì²´ ë‚´ìš©ì´ë‹¤:\n{html}"},
            {"role": "user", "content": instruction},
        ]
    )

    result = resp.choices[0].message.content.strip()

    print("ğŸ˜ GPT ê²°ê³¼: \n", result)
    return result

# ---------------------------
# ìŠ¬ë¼ì´ë“œ ì €ì¥ í•¨ìˆ˜
# ---------------------------
def save_slide_json(slide_num: int, slide_json: dict):
    timestamp = datetime.now().strftime("%Y%m%d-%H%M%S")
    out_path = OUTPUT_DIR / f"slide{slide_num}_{timestamp}.json"
    with out_path.open("w", encoding="utf-8") as f:
        json.dump(slide_json, f, ensure_ascii=False, indent=2)
    print(f"âœ… slide{slide_num} ì €ì¥ ì™„ë£Œ â†’ {out_path}")


# ---------------------------
# ë©”ì¸ ë°°ì¹˜ ì²˜ë¦¬
# ---------------------------
def main():
    # 1) HTML ë¡œë“œ (ìˆ˜ì • í•„ìš” ì‹œ ì´ ë¶€ë¶„ë§Œ êµì²´)
    with open(DATA_PATH, "r", encoding="utf-8") as f:
        html = f.read()

    # 2) ë°°ì¹˜ ê·¸ë£¹ ì •ì˜
    batches = [
        (1, 3, "í‘œì§€ + ì™¸ë‚´ë¶€ë™ê¸° + ì•„ì´í…œí•„ìš”ì„±"),
        (4, 5, "TAMÂ·SAMÂ·SOM + ì‹œì¥ë¶„ì„"),
        (6, 8, "í•´ê²°ë°©ì•ˆ + í•µì‹¬ê°€ì¹˜ + ê°œë°œë°©ì•ˆ"),
        (9, 10, "ê³ ê°ê²€ì¦ + ê²½ìŸì‚¬ë¶„ì„ ë° ê²½ìŸë ¥"),
        (11, 14, "ë¹„ì¦ˆë‹ˆìŠ¤ëª¨ë¸ + ìˆ˜ìµëª¨ë¸ + ì‹œì¥ì „ëµ + ì„±ê³¼"),
        (15, 16, "ë¡œë“œë§µ + ìê¸ˆì¡°ë‹¬ ë° ì†Œìš”ê³„íš"),
        (17, 18, "íŒ€ì†Œê°œ + ë¹„ì „ ë° ê²°ë¡ "),
    ]

    # 3) ê° ë°°ì¹˜ ì‹¤í–‰
    for (start, end, desc) in batches:
        print(f"\nğŸš€ [ë°°ì¹˜ {start}-{end}] {desc} ìƒì„± ì¤‘...")

        prompt = ""
        for i in range(start, end+1):
            prompt += "="*10 + "\n" + f"í•´ë‹¹ìŠ¬ë¼ì´ë“œë²ˆí˜¸ëŠ” {i} ìŠ¬ë¼ì´ë“œì…ë‹ˆë‹¤. ì¶”ì¶œ í”„ë¡¬í”„íŠ¸ëŠ” ë‹¤ìŒê³¼ ê°™ìŠµë‹ˆë‹¤.\n >>" + build_prompt(i) + "\n" + "="*10 + "\n"


        instruction = f"""
ì•„ë˜ HTML ë¬¸ì„œë¥¼ ê¸°ë°˜ìœ¼ë¡œ, ìŠ¬ë¼ì´ë“œ {start}~{end}ì— í•´ë‹¹í•˜ëŠ” ë‚´ìš©ì„ ê°ê° ë…ë¦½ëœ JSON ê°ì²´ë¡œ ìƒì„±í•˜ì„¸ìš”.
ê° ìŠ¬ë¼ì´ë“œëŠ” --- ë¡œ êµ¬ë¶„í•˜ì„¸ìš”.
JSON êµ¬ì¡°ëŠ” ìŠ¬ë¼ì´ë“œë³„ ì •ì˜ë¥¼ ì—„ê²©íˆ ë”°ë¼ì•¼ í•˜ë©°, ë¶ˆí•„ìš”í•œ ì„¤ëª…ë¬¸ì´ë‚˜ ì½”ë“œ ë¸”ë¡ì€ í¬í•¨í•˜ì§€ ë§ˆì„¸ìš”.

[ê°€ì¥ ì¤‘ìš”]
** ìŠ¬ë¼ì´ë“œë³„ ì¶”ì¶œ í˜•ì‹ì„ ëª…ì‹¬í•˜ì„¸ìš”! **
** ì¶”ì¶œí˜•ì‹ì—ì„œ ì œì‹œëœ json í‚¤ê°’ì„ ìˆ˜ì •í•˜ë©´ ì ˆëŒ€ ì•ˆë©ë‹ˆë‹¤. ê·¸ëŒ€ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤. ìƒˆë¡œìš´ í‚¤ë¥¼ ì¶”ê°€í•˜ê±°ë‚˜ ì´ë¦„ì„ ë°”ê¾¸ì§€ ë§ˆì„¸ìš”. **
**JSON êµ¬ì¡°(ì¤‘ê´„í˜¸Â·ëŒ€ê´„í˜¸Â·ì‰¼í‘œÂ·ë”°ì˜´í‘œ)ì™€ í•„ë“œ ìˆœì„œëŠ” ì˜ˆì‹œì™€ ë™ì¼í•˜ê²Œ ìœ ì§€í•˜ì„¸ìš”.**
** ìµœì¢… ì¶”ì¶œë˜ëŠ” json ê°ì²´ëŠ” {end-start+1}ê°œì…ë‹ˆë‹¤.**
        """ + prompt

        print('í”„ë¡¬í”„íŠ¸: ', instruction)

        results = call_gpt_with_context(html, instruction)
        
        output_dir = Path("/Users/chanchan/Downloads/MVP IR DECK (3)/slides")
        save_split_json_results(results, start, end , output_dir)

        # for i, slide_json in enumerate(results, start=start):
        #     save_slide_json(i, slide_json)

        print(f"âœ… ë°°ì¹˜ {start}-{end} ì™„ë£Œ ({end-start+1}ê°œ ìŠ¬ë¼ì´ë“œ)\n")

    print("\n ëª¨ë“  ë°°ì¹˜(8ë©ì–´ë¦¬) ìƒì„± ì™„ë£Œ!")


if __name__ == "__main__":
    main()